{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ce2cf6-540a-4eb8-8b34-6fbebd64b096",
   "metadata": {},
   "source": [
    "# Handwritten Number Recognition Model (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8979ac78-cd55-4d91-993f-b67156dbd116",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f60ed279-2060-429f-ab0e-2488e6da8651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import easyocr\n",
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fa06d6-f8d1-45d9-afe0-bef8c24dccbf",
   "metadata": {},
   "source": [
    "## Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b19fc2be-f5f5-40e1-b611-ced8cf94392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train) , (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b6fd73-860d-44a0-a682-abd300086b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_train), np.shape(y_train))\n",
    "print(np.shape(x_test), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b4d3f-feae-4170-a2e3-1ba98fb8598d",
   "metadata": {},
   "source": [
    "60000 samples of 28x28 px in train \\\n",
    "10000 samples of 28x28 px in test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe0df75-6926-4a36-a62e-ce6428cddc9c",
   "metadata": {},
   "source": [
    "## Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb751b7a-cb12-4558-8914-9b57ad86b6ff",
   "metadata": {},
   "source": [
    "We reshape it to 28,28,1 because Conv2D expects color value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf6c811-d2c0-46ef-b9af-54b10645b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x_train.reshape(60000, 28,28,1) , y_train.reshape(60000, 1)\n",
    "x_test, y_test = x_test.reshape(10000, 28,28,1) , y_test.reshape(10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19256ba4-ae30-440d-84aa-8a634008c093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000, 1)\n",
      "(10000, 28, 28, 1) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_train), np.shape(y_train))\n",
    "print(np.shape(x_test), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b05e93-ec61-4223-a05d-b1d30a433916",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f772fb2-48b9-4c5c-9ef0-42ab328c00fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train/255.0 , x_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba6b9bf-54ca-43e1-967e-7d05ebf37a60",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b05606a-3f1e-4c7e-8a26-be8097fb3a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a55791aa-576d-4a0a-af50-7ba639057969",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape = (28,28,1)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd0233a1-6db8-429b-8748-e5d7ae09a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63950491-4918-4466-bbb0-3557bcc0d902",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7362e895-a58c-4190-854e-dfa4f4196e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9969 - loss: 0.0103 - val_accuracy: 0.9915 - val_loss: 0.0336\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9985 - loss: 0.0062 - val_accuracy: 0.9919 - val_loss: 0.0321\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.9921 - val_loss: 0.0330\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 0.9924 - val_loss: 0.0337\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.9916 - val_loss: 0.0349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23229683f20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = x_train , y = y_train, validation_split = 0.2, epochs = 5, batch_size = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0402c3fe-b85e-4cb0-970a-ed36e3228490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9903 - loss: 0.0323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02434762381017208, 0.9927999973297119]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354e5da4-972b-4884-ad19-3382e2c1e576",
   "metadata": {},
   "source": [
    "# OCR/ CNN function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e087ea6-0290-4d42-aba8-53cd4b3f7759",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f8046e2-f7a1-4358-9d99-aefb84e1c76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_prediction(img_obj):\n",
    "    image = img_obj\n",
    "    def remove_borders(image, border_size=5):\n",
    "        # Crop out the borders by a fixed size\n",
    "        return image[border_size:-border_size, border_size:-border_size]\n",
    "    # Remove borders from the entire image\n",
    "    image = remove_borders(image, border_size=5)\n",
    "\n",
    "    image = cv2. cvtColor(image, cv2. COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply binary thresholding to the image\n",
    "    _, thresh = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Sort contours by their x position\n",
    "    contours = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "    \n",
    "    digits = []\n",
    "\n",
    "    global num\n",
    "    num = 0\n",
    "\n",
    "    for ctr in contours:\n",
    "        num = num*10\n",
    "        # Get bounding box for each contour\n",
    "        x, y, w, h = cv2.boundingRect(ctr)\n",
    "        \n",
    "        # Add padding to the bounding box\n",
    "        padding = 5  # Adjust padding as needed\n",
    "        x = max(x - padding, 0)\n",
    "        y = max(y - padding, 0)\n",
    "        w = min(w + 2 * padding, image.shape[1] - x)\n",
    "        h = min(h + 2 * padding, image.shape[0] - y)\n",
    "        \n",
    "        # Extract the digit using the bounding box\n",
    "        digit = thresh[y:y+h, x:x+w]\n",
    "        \n",
    "        # Resize the digit to 28x28 pixels\n",
    "        resized_digit = cv2.resize(digit, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Normalize the digit\n",
    "        digit = resized_digit / 255.0\n",
    "        num = num + np.argmax(model.predict(digit.reshape(1,28,28,1)))\n",
    "    return num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f627e7c-a601-4838-9263-b24483d39c35",
   "metadata": {},
   "source": [
    "## OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5d699a23-3c46-49ff-9b6e-bb6816159135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_prediction(img_obj):\n",
    "    try:\n",
    "        results = reader.readtext(img_obj)\n",
    "        result_set = set()\n",
    "        if len(results) > 1:\n",
    "            for x in results[0][1]:\n",
    "                result_set.add(x)\n",
    "            for x in results[1][1]:\n",
    "                result_set.add(x)\n",
    "            attention = False\n",
    "            if  len( (results[0][1])+(results[1][1]) ) - len(result_set) > 5:\n",
    "                attention = True\n",
    "        if results:\n",
    "            return results\n",
    "        else:\n",
    "            return 'ERR'\n",
    "    except Exception as e:\n",
    "        return 'ERR'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b36ae3-471c-42db-9293-0e8036de87cb",
   "metadata": {},
   "source": [
    "# Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5af90ebb-d3a8-43c3-b649-1048f5c4288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymupdf \n",
    "import pymupdf\n",
    "import io\n",
    "import os\n",
    "from PIL import Image as PILImage\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "ebc463f7-53c9-45ed-8288-741ecf3026da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "49690ddb-61a5-4045-9e41-7f689f413455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(pdf_path):\n",
    "    pdf_document = pymupdf.open(pdf_path)\n",
    "    global rows_written\n",
    "    rows_written = 0\n",
    "\n",
    "    if not os.path.exists('outputs'):\n",
    "        os.makedirs('outputs')\n",
    "    \n",
    "    \n",
    "    #Clearing any past file\n",
    "    with open('outputs/output.csv', mode='w') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "    with open('outputs/attention.txt', mode='w') as txt_file:\n",
    "        txt_write = txt_file.write('')\n",
    "   \n",
    "    for page_number in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_number)\n",
    "        # To image (using matrix transformation)\n",
    "        zoom = 2  # Adjust zoom level as needed\n",
    "        mat = pymupdf.Matrix(zoom, zoom)\n",
    "        pix = page.get_pixmap(matrix=mat, alpha=False)\n",
    "\n",
    "        # pixmap to PIL Image\n",
    "        img_bytes = pix.tobytes(\"ppm\")\n",
    "        image = PILImage.open(io.BytesIO(img_bytes))\n",
    "\n",
    "        image = np.array(image)\n",
    "        get_table(image, page_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "78511a6c-7ae6-45f0-ab2e-8d75c2a5a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(image_name, page_no):\n",
    "    image = image_name\n",
    "    \n",
    "    ## Filters\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    \n",
    "    \n",
    "    ## Contour detection\n",
    "    contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:1]\n",
    "    table_contour = None\n",
    "    for contour in contours:\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
    "    \n",
    "        if len(approx) == 4:\n",
    "            table_contour = approx\n",
    "            break\n",
    "    \n",
    "    if table_contour is not None:\n",
    "        # Get bounding box coordinates\n",
    "        x, y, w, h = cv2.boundingRect(table_contour)\n",
    "    \n",
    "        # Crop the table region from the original image\n",
    "        table_image = image[y:y+h, x:x+w]\n",
    "        num_rows = 0\n",
    "        extract_cells_to_csv(table_image, page_no)\n",
    "    else:\n",
    "        print(\"error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "2179742d-41db-4ded-9de4-f9d5883a2f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cells_to_csv(table_image,  page_no, csv_filename='outputs/output.csv'):\n",
    "    image = table_image\n",
    "    \n",
    "    # Determine number of rows using page height\n",
    "    # height = 181 + 59*rows\n",
    "    height = len(image)\n",
    "    num_rows = round((height - 181) / 59)\n",
    "    global rows_written\n",
    "    \n",
    "    # Parameters (adjust these values as needed)\n",
    "    title_offset = 106 + (num_rows * 2)  # Offset to skip the title\n",
    "    header_row_height = 75  # Height of the header row\n",
    "    row_height = 57  # Height of each subsequent row\n",
    "    \n",
    "    # Column widths (adjust these values according to your table)\n",
    "    col_names = [\"SNo.\",\"ID\",\"NAME\",\"DOB\",\"INTERVIEW MARKS\"]\n",
    "    column_widths = [67, 73, 392 + (num_rows * 2), 175, 380]\n",
    "    \n",
    "    # Function to get the column boundaries\n",
    "    def get_column_boundaries(column_widths):\n",
    "        boundaries = [0]\n",
    "        for width in column_widths:\n",
    "            boundaries.append(boundaries[-1] + width)\n",
    "        return boundaries\n",
    "    \n",
    "    column_boundaries = get_column_boundaries(column_widths)\n",
    "    \n",
    "    # Open a CSV file to write the results\n",
    "    with open(csv_filename, mode='a', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        \n",
    "        # Extract header row\n",
    "        header_row = image[title_offset:title_offset + header_row_height, :]\n",
    "        header_cells = []\n",
    "        \n",
    "        # Process each cell of the header row\n",
    "        if page_no == 0:\n",
    "            for col in range(0,5):\n",
    "                cell = header_row[:, column_boundaries[col]:column_boundaries[col + 1]]\n",
    "                cell_image = np.array(cell)\n",
    "                header_cells.append(ocr_prediction(cell_image)[0][1])\n",
    "            \n",
    "            # Write the header row to the CSV\n",
    "            csv_writer.writerow(header_cells)\n",
    "        \n",
    "        # Extract subsequent rows\n",
    "        for row in range(1, num_rows + 1):\n",
    "            row_start = title_offset + header_row_height + (row - 1) * row_height\n",
    "            row_end = row_start + row_height\n",
    "            table_row = image[row_start:row_end, :]\n",
    "            row_cells = []\n",
    "            \n",
    "            # Process each cell of the row\n",
    "            row_cells.append(f'{row + rows_written}')\n",
    "            for col in range(1,5):\n",
    "                cell = table_row[:, column_boundaries[col]:column_boundaries[col + 1]]\n",
    "                cell_image = np.array(cell)\n",
    "                if col < 4:\n",
    "                   row_cells.append(ocr_prediction(cell_image)[0][1])\n",
    "                   if len(ocr_prediction(cell_image)) > 1:\n",
    "                       txt_file = open(\"outputs/attention.txt\", \"a\", newline=\"\\n\")\n",
    "                       txt_file.write(f\"Attention needed at: SNo. {rows_written + row} , {col_names[col]} \\n\")\n",
    "                if col == 4:\n",
    "                    row_cells.append(hand_prediction(cell_image))\n",
    "            \n",
    "            # Write the row to the CSV\n",
    "            csv_writer.writerow(row_cells)\n",
    "            \n",
    "    print(f\"Written {num_rows} row(s) to '{csv_filename}'.\")\n",
    "    rows_written += num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "d3267a87-3461-4a06-a484-9e71dececff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Written 6 row(s) to 'outputs/output.csv'.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Written 8 row(s) to 'outputs/output.csv'.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Written 3 row(s) to 'outputs/output.csv'.\n"
     ]
    }
   ],
   "source": [
    "read_pdf(\"demo1.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
